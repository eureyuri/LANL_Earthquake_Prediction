{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Our final project is on predicting Earthquakes, use features created from feature_extraction, begin by defining helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a4f313097635>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# use kernals in Kaggle\n",
    "\n",
    "# imports \n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import altair as alt\n",
    "from altair.vega import v3\n",
    "from IPython.display import HTML\n",
    "\n",
    "# had issues using this particular kaggle repository, so simply copied the code for artgor_utils here\n",
    "class artgor_utils:\n",
    "    def prepare_altair():\n",
    "        \"\"\"\n",
    "        Helper function to prepare altair for working.\n",
    "        \"\"\"\n",
    "\n",
    "        vega_url = 'https://cdn.jsdelivr.net/npm/vega@' + v3.SCHEMA_VERSION\n",
    "        vega_lib_url = 'https://cdn.jsdelivr.net/npm/vega-lib'\n",
    "        vega_lite_url = 'https://cdn.jsdelivr.net/npm/vega-lite@' + alt.SCHEMA_VERSION\n",
    "        vega_embed_url = 'https://cdn.jsdelivr.net/npm/vega-embed@3'\n",
    "        noext = \"?noext\"\n",
    "\n",
    "        paths = {\n",
    "            'vega': vega_url + noext,\n",
    "            'vega-lib': vega_lib_url + noext,\n",
    "            'vega-lite': vega_lite_url + noext,\n",
    "            'vega-embed': vega_embed_url + noext\n",
    "        }\n",
    "\n",
    "        workaround = f\"\"\"    requirejs.config({{\n",
    "            baseUrl: 'https://cdn.jsdelivr.net/npm/',\n",
    "            paths: {paths}\n",
    "        }});\n",
    "        \"\"\"\n",
    "\n",
    "        return workaround\n",
    "\n",
    "\n",
    "    def add_autoincrement(render_func):\n",
    "        # Keep track of unique <div/> IDs\n",
    "        cache = {}\n",
    "        def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n",
    "            if autoincrement:\n",
    "                if id in cache:\n",
    "                    counter = 1 + cache[id]\n",
    "                    cache[id] = counter\n",
    "                else:\n",
    "                    cache[id] = 0\n",
    "                actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n",
    "            else:\n",
    "                if id not in cache:\n",
    "                    cache[id] = 0\n",
    "                actual_id = id\n",
    "            return render_func(chart, id=actual_id)\n",
    "        # Cache will stay outside and \n",
    "        return wrapped\n",
    "\n",
    "\n",
    "    @add_autoincrement\n",
    "    def render(chart, id=\"vega-chart\"):\n",
    "        \"\"\"\n",
    "        Helper function to plot altair visualizations.\n",
    "        \"\"\"\n",
    "        chart_str = \"\"\"\n",
    "        <div id=\"{id}\"></div><script>\n",
    "        require([\"vega-embed\"], function(vg_embed) {{\n",
    "            const spec = {chart};     \n",
    "            vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n",
    "            console.log(\"anything?\");\n",
    "        }});\n",
    "        console.log(\"really...anything?\");\n",
    "        </script>\n",
    "        \"\"\"\n",
    "        return HTML(\n",
    "            chart_str.format(\n",
    "                id=id,\n",
    "                chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "    def train_model_regression(X, X_test, y, params, folds, model_type='lgb', eval_metric='mae', columns=None, plot_feature_importance=False, model=None):\n",
    "        \"\"\"\n",
    "        A function to train a variety of regression models.\n",
    "        Returns dictionary with oof predictions, test predictions, scores and, if necessary, feature importances.\n",
    "\n",
    "        :params: X - training data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "        :params: X_test - test data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "        :params: y - target\n",
    "        :params: folds - folds to split data\n",
    "        :params: model_type - type of model to use\n",
    "        :params: eval_metric - metric to use\n",
    "        :params: columns - columns to use. If None - use all columns\n",
    "        :params: plot_feature_importance - whether to plot feature importance of LGB\n",
    "        :params: model - sklearn model, works only for \"sklearn\" model type\n",
    "\n",
    "        \"\"\"\n",
    "        columns = X.columns if columns == None else columns\n",
    "        X_test = X_test[columns]\n",
    "\n",
    "        # to set up scoring parameters\n",
    "        metrics_dict = {'mae': {'lgb_metric_name': 'mae',\n",
    "                            'catboost_metric_name': 'MAE',\n",
    "                            'sklearn_scoring_function': metrics.mean_absolute_error}}\n",
    "\n",
    "        result_dict = {}\n",
    "\n",
    "        # out-of-fold predictions on train data\n",
    "        oof = np.zeros(len(X))\n",
    "\n",
    "        # averaged predictions on train data\n",
    "        prediction = np.zeros(len(X_test))\n",
    "\n",
    "        # list of scores on folds\n",
    "        scores = []\n",
    "        feature_importance = pd.DataFrame()\n",
    "\n",
    "        # split and train on folds\n",
    "        for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "            print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
    "            if type(X) == np.ndarray:\n",
    "                X_train, X_valid = X[columns][train_index], X[columns][valid_index]\n",
    "                y_train, y_valid = y[train_index], y[valid_index]\n",
    "            else:\n",
    "                X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "                y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "\n",
    "            if model_type == 'lgb':\n",
    "                model = lgb.LGBMRegressor(**params, n_estimators = 500000, n_jobs = -1)\n",
    "                model.fit(X_train, y_train, \n",
    "                        eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n",
    "                        verbose=100000, early_stopping_rounds=2000)\n",
    "\n",
    "                y_pred_valid = model.predict(X_valid)\n",
    "                y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "\n",
    "            if model_type == 'xgb':\n",
    "                train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
    "                valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
    "\n",
    "                watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "                model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=500, params=params)\n",
    "                y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "                y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "            if model_type == 'sklearn':\n",
    "                model = model\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "                score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n",
    "                print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n",
    "                print('')\n",
    "\n",
    "                y_pred = model.predict(X_test).reshape(-1,)\n",
    "\n",
    "            if model_type == 'cat':\n",
    "                model = CatBoostRegressor(iterations=20000,  eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params,\n",
    "                                          loss_function=metrics_dict[eval_metric]['catboost_metric_name'])\n",
    "                model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "                y_pred_valid = model.predict(X_valid)\n",
    "                y_pred = model.predict(X_test)\n",
    "\n",
    "            oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n",
    "\n",
    "            prediction += y_pred    \n",
    "\n",
    "            if model_type == 'lgb' and plot_feature_importance:\n",
    "                # feature importance\n",
    "                fold_importance = pd.DataFrame()\n",
    "                fold_importance[\"feature\"] = columns\n",
    "                fold_importance[\"importance\"] = model.feature_importances_\n",
    "                fold_importance[\"fold\"] = fold_n + 1\n",
    "                feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "        prediction /= folds.n_splits\n",
    "\n",
    "        print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "\n",
    "        result_dict['oof'] = oof\n",
    "        result_dict['prediction'] = prediction\n",
    "        result_dict['scores'] = scores\n",
    "\n",
    "        if model_type == 'lgb':\n",
    "            if plot_feature_importance:\n",
    "                feature_importance[\"importance\"] /= folds.n_splits\n",
    "                cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                    by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "                best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "                plt.figure(figsize=(16, 12));\n",
    "                sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "                plt.title('LGB Features (avg over folds)');\n",
    "\n",
    "                result_dict['feature_importance'] = feature_importance\n",
    "\n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pd.options.display.precision = 15\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn import svm\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import datetime\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import linear_model\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.ensemble import ExtraTreesRegressor, AdaBoostRegressor\n",
    "\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import hann\n",
    "from scipy.signal import convolve\n",
    "from scipy import stats\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import librosa, librosa.display\n",
    "import builtins\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import eli5\n",
    "import shap\n",
    "from sklearn.feature_selection import GenericUnivariateSelect, SelectPercentile, SelectKBest, f_classif, mutual_info_classif, RFE\n",
    "\n",
    "from IPython.display import HTML\n",
    "import json\n",
    "import altair as alt\n",
    "\n",
    "workaround = artgor_utils.prepare_altair()\n",
    "HTML(\"\".join((\n",
    "    \"<script>\",\n",
    "    workaround,\n",
    "    \"</script>\",\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import features\n",
    "train_features = pd.read_csv('../input/lanl-features/train_features.csv')\n",
    "test_features = pd.read_csv('../input/lanl-features/test_features.csv')\n",
    "train_features_denoised = pd.read_csv('../input/lanl-features/train_features_denoised.csv')\n",
    "test_features_denoised = pd.read_csv('../input/lanl-features/test_features_denoised.csv')\n",
    "train_features_denoised.columns = [f'{i}_denoised' for i in train_features_denoised.columns]\n",
    "test_features_denoised.columns = [f'{i}_denoised' for i in test_features_denoised.columns]\n",
    "y = pd.read_csv('../input/lanl-features/y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([train_features, train_features_denoised], axis=1).drop(['seg_id_denoised', 'target_denoised'], axis=1)\n",
    "X_test = pd.concat([test_features, test_features_denoised], axis=1).drop(['seg_id_denoised', 'target_denoised'], axis=1)\n",
    "X = X[:-1]\n",
    "y = y[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "params = {'num_leaves': 128,\n",
    "          'min_child_samples': 79,\n",
    "#           'objective': 'gamma',\n",
    "          'max_depth': 1, # -1\n",
    "          'learning_rate': 0.001, # 0.01\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"subsample_freq\": 5,\n",
    "          \"subsample\": 0.98, # 0.90\n",
    "          \"bagging_seed\": 12,\n",
    "          \"metric\": 'mae',\n",
    "          \"verbosity\": 1, #-1\n",
    "          'reg_alpha': 0.1302650970728192,\n",
    "          'reg_lambda': 0.3603427518866501,\n",
    "          'colsample_bytree': 0.01\n",
    "         }\n",
    "result_dict_lgb = train_model_regression(X=X, X_test=X_test, y=y, params=params, folds=folds, model_type='xgb',\n",
    "                                                                                  eval_metric='mae', plot_feature_importance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the sample submission for the structure to save our results to\n",
    "submission = pd.read_csv('../input/LANL-Earthquake-Prediction/sample_submission.csv', index_col='seg_id')\n",
    "submission['time_to_failure'] = result_dict_lgb['prediction']\n",
    "print(submission.head())\n",
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X), columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply k-Nearest Neighbors\n",
    "\n",
    "n = 10\n",
    "neigh = NearestNeighbors(n, n_jobs=-1)\n",
    "neigh.fit(X_train_scaled)\n",
    "\n",
    "dists, _ = neigh.kneighbors(X_train_scaled, n_neighbors=n)\n",
    "mean_dist = dists.mean(axis=1)\n",
    "max_dist = dists.max(axis=1)\n",
    "min_dist = dists.min(axis=1)\n",
    "\n",
    "X_train_scaled['mean_dist'] = mean_dist\n",
    "X_train_scaled['max_dist'] = max_dist\n",
    "X_train_scaled['min_dist'] = min_dist\n",
    "\n",
    "test_dists, _ = neigh.kneighbors(X_test_scaled, n_neighbors=n)\n",
    "\n",
    "test_mean_dist = test_dists.mean(axis=1)\n",
    "test_max_dist = test_dists.max(axis=1)\n",
    "test_min_dist = test_dists.min(axis=1)\n",
    "\n",
    "X_test_scaled['mean_dist'] = test_mean_dist\n",
    "X_test_scaled['max_dist'] = test_max_dist\n",
    "X_test_scaled['min_dist'] = test_min_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 32,\n",
    "          'min_data_in_leaf': 79,\n",
    "          'objective': 'gamma',\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.01,\n",
    "          \"boosting\": \"gbdt\",\n",
    "          \"bagging_freq\": 5,\n",
    "          \"bagging_fraction\": 0.8126672064208567,\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'mae',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.1302650970728192,\n",
    "          'reg_lambda': 0.3603427518866501,\n",
    "          'feature_fraction': 0.1\n",
    "         }\n",
    "result_dict_lgb = artgor_utils.train_model_regression(X=X, X_test=X_test, y=y, params=params, folds=folds, model_type='lgb',\n",
    "                                                                                  eval_metric='mae', plot_feature_importance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how this method worked\n",
    "submission['time_to_failure'] = result_dict_lgb['prediction']\n",
    "submission.to_csv('submission_nn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try eli5, note this one takes a long time\n",
    "top_columns = ['iqr1_denoised', 'percentile_5_denoised', 'abs_percentile_90_denoised', 'percentile_95_denoised', 'ave_roll_std_10', 'num_peaks_10', 'percentile_roll_std_20',\n",
    "               'ratio_unique_values_denoised', 'fftr_percentile_roll_std_75_denoised', 'num_crossing_0_denoised', 'percentile_95', 'ffti_percentile_roll_std_75_denoised',\n",
    "               'min_roll_std_10000', 'percentile_roll_std_1', 'percentile_roll_std_10', 'fftr_percentile_roll_std_70_denoised', 'ave_roll_std_50', 'ffti_percentile_roll_std_70_denoised',\n",
    "               'exp_Moving_std_300_mean_denoised', 'ffti_percentile_roll_std_30_denoised', 'mean_change_rate', 'percentile_roll_std_5', 'range_-1000_0', 'mad',\n",
    "               'fftr_range_1000_2000_denoised', 'percentile_10_denoised', 'ffti_percentile_roll_std_80', 'percentile_roll_std_25', 'fftr_percentile_10_denoised',\n",
    "               'ffti_range_-2000_-1000_denoised', 'autocorrelation_5', 'min_roll_std_100', 'fftr_percentile_roll_std_80', 'min_roll_std_500', 'min_roll_std_50', 'min_roll_std_1000',\n",
    "               'ffti_percentile_20_denoised', 'iqr1', 'classic_sta_lta5_mean_denoised', 'classic_sta_lta6_mean_denoised', 'percentile_roll_std_10_denoised',\n",
    "               'fftr_percentile_70_denoised', 'ffti_c3_50_denoised', 'ffti_percentile_roll_std_75', 'abs_percentile_90', 'range_0_1000', 'spkt_welch_density_50_denoised',\n",
    "               'ffti_percentile_roll_std_40_denoised', 'ffti_range_-4000_-3000', 'mean_change_rate_last_50000']\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X[top_columns], y, test_size=0.1)\n",
    "model = lgb.LGBMRegressor(**params, n_estimators = 50000, n_jobs = -1, verbose=-1)\n",
    "model.fit(X_train, y_train, \n",
    "        eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='mae',\n",
    "        verbose=10000, early_stopping_rounds=200)\n",
    "\n",
    "perm = eli5.sklearn.PermutationImportance(model, random_state=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_weights(perm, top=50, feature_names=top_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = [i for i in eli5.formatters.as_dataframe.explain_weights_df(model).feature if 'BIAS' not in i][:40]\n",
    "result_dict_lgb = artgor_utils.train_model_regression(X, X_test, y, params=params, folds=folds, model_type='lgb', plot_feature_importance=True, columns=top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['time_to_failure'] = result_dict_lgb['prediction']\n",
    "submission.to_csv('submission_eli5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "params = {'num_leaves': 32,\n",
    "          'min_child_samples': 79,\n",
    "          'objective': 'gamma',\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.01,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"subsample_freq\": 5,\n",
    "          \"subsample\": 0.9,\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'mae',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.1302650970728192,\n",
    "          'reg_lambda': 0.3603427518866501,\n",
    "          'colsample_bytree': 1.0\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict = {'f_classif': [2.0746468465171377, 2.0753843541953687, 2.062191535440333, 2.0654327826583034, 2.0643551320704936, 2.0617560048382675,\n",
    "                             2.061565197738015, 2.0598878198917494, 2.0654865223333143, 2.0632788555735777, 2.058002635080971, 2.051075689018734,\n",
    "                             2.0472543961304583, 2.052401474353084, 2.055924154798443, 2.0561794619762352, 2.0549680611994963, 2.057123777802326,\n",
    "                             2.0591868861136904, 2.0577745274024553],\n",
    "               'mutual_info_classif': [2.0866763775014006, 2.0745431497064324, 2.0564324832516427, 2.060125564781158, 2.067334544167612, 2.0665943783246448,\n",
    "                                       2.063891669849029, 2.070194051004794, 2.0667490707700447, 2.0681653852378354, 2.0592743636982345, 2.061260741522344,\n",
    "                                       2.05680667824411, 2.0565047875243003, 2.058252567141659, 2.0554927194831922, 2.0562776429736873, 2.0618179277444084,\n",
    "                                       2.06364125584214, 2.0577745274024553],\n",
    "               'n_features': [98, 196, 294, 392, 490, 588, 685, 783, 881, 979, 1077, 1175, 1273, 1370, 1468, 1566, 1664, 1762, 1860, 1958]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(scores_dict)\n",
    "scores_df = scores_df.melt(id_vars=['n_features'], value_vars=['mutual_info_classif', 'f_classif'], var_name='metric', value_name='mae')\n",
    "max_value = scores_df['mae'].max() * 1.05\n",
    "min_value = scores_df['mae'].min() * 0.95\n",
    "artgor_utils.render(alt.Chart(scores_df).mark_line().encode(\n",
    "    y=alt.Y('mae:Q', scale=alt.Scale(domain=(min_value, max_value))),\n",
    "    x='n_features:O',\n",
    "    color='metric:N',\n",
    "    tooltip=['metric:N', 'n:O', 'mae:Q']\n",
    ").properties(\n",
    "    title='Top N features by SelectPercentile vs CV'\n",
    ").interactive())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectKBest\n",
    "\n",
    "**Important notice**:  I run the cell below in `version 14` and printed the scores_dict. In the following versions I'll use `scores_dict` and plot the results instead of running feature selection each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict = {'f_classif': [2.1495892622081354, 2.0778182269587147, 2.0716153738740006, 2.06152950679902, 2.0645162758752553, 2.0627705797004032, 2.0610992303725157,\n",
    "                             2.057762113735462, 2.0618360883613627, 2.0603197111525984, 2.06081274633874, 2.0580767195278056, 2.0527646572747127, 2.0498353445032533,\n",
    "                             2.052442594925, 2.0564456881902133, 2.0582284644115365, 2.0558612960548635, 2.0580900016350094, 2.058218782401599],\n",
    "               'mutual_info_classif': [2.1235703196243687, 2.084958198672301, 2.0596822478390955, 2.053305869981444, 2.063468853227225, 2.0674399950434323, 2.0658618511287874,\n",
    "                                       2.063003703200445, 2.0653174905858664, 2.0644340327023656, 2.0748993062333523, 2.0587602096358113, 2.0601495560836076, 2.0559629138548603,\n",
    "                                       2.0553852701221134, 2.058022171415446, 2.060755947658241, 2.057916705462307, 2.056245795262636, 2.0580691870837056],\n",
    "               'n_features': [10, 110, 210, 310, 410, 510, 610, 710, 810, 910, 1010, 1110, 1210, 1310, 1410, 1510, 1610, 1710, 1810, 1910]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(scores_dict)\n",
    "scores_df = scores_df.melt(id_vars=['n_features'], value_vars=['mutual_info_classif', 'f_classif'], var_name='metric', value_name='mae')\n",
    "max_value = scores_df['mae'].max() * 1.05\n",
    "min_value = scores_df['mae'].min() * 0.95\n",
    "artgor_utils.render(alt.Chart(scores_df).mark_line().encode(\n",
    "    y=alt.Y('mae:Q', scale=alt.Scale(domain=(min_value, max_value))),\n",
    "    x='n_features:O',\n",
    "    color='metric:N',\n",
    "    tooltip=['metric:N', 'n:O', 'mae:Q']\n",
    ").properties(\n",
    "    title='Top N features by SelectKBest vs CV'\n",
    ").interactive())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the huge number of features there are certainly some highly correlated features, let's try droping them!\n",
    "# https://chrisalbon.com/machine_learning/feature_selection/drop_highly_correlated_features/\n",
    "corr_matrix = X.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.99)]\n",
    "X = X.drop(to_drop, axis=1)\n",
    "X_test = X_test.drop(to_drop, axis=1)\n",
    "result_dict_lgb_lgb = artgor_utils.train_model_regression(X, X_test, y, params=params, folds=folds, model_type='lgb', plot_feature_importance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as before, lets check how the model works when we drop highly correlated features\n",
    "submission['time_to_failure'] = result_dict_lgb['prediction']\n",
    "submission.to_csv('submission_no_corr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict = {'rfe_score': [2.103586938061856, 2.052535910798748, 2.053228199447811], 'n_features': [10, 110, 210]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(scores_dict)\n",
    "scores_df = scores_df.melt(id_vars=['n_features'], value_vars=['rfe_score'], var_name='metric', value_name='mae')\n",
    "max_value = scores_df['mae'].max() * 1.05\n",
    "min_value = scores_df['mae'].min() * 0.95\n",
    "artgor_utils.render(alt.Chart(scores_df).mark_line().encode(\n",
    "    y=alt.Y('mae:Q', scale=alt.Scale(domain=(min_value, max_value))),\n",
    "    x='n_features:O',\n",
    "    color='metric:N',\n",
    "    tooltip=['metric:N', 'n:O', 'mae:Q']\n",
    ").properties(\n",
    "    title='Top N features by RFE vs CV'\n",
    ").interactive())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
